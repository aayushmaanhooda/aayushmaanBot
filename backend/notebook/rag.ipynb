{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "792ffdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa0f6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing Pinecone vector store \n",
    "\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "index_name = \"aayushbot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name = index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "# index \n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings, namespace=\"aayush-docs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edd6c5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already indexed, skipping\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "A hash is a unique fingerprint of a file. \n",
    "If file content changes even by one character, the hash completely changes. \n",
    "If file is same, hash is always same.\n",
    "\n",
    "'''\n",
    "import hashlib\n",
    "import os\n",
    "import json\n",
    "\n",
    "INDEXED_FILE = \"indexed_docs.json\"\n",
    "\n",
    "def get_file_hash(path):\n",
    "    return hashlib.md5(open(path, \"rb\").read()).hexdigest()\n",
    "\n",
    "\n",
    "def is_already_indexed(filename, file_hash):\n",
    "    if not os.path.exists(INDEXED_FILE):  # if json file doesn't exist yet\n",
    "        return False                       # nothing indexed, return False\n",
    "    db = json.load(open(INDEXED_FILE))    # load the json as a dict\n",
    "    return db.get(filename) == file_hash  # check if stored hash matches current hash\n",
    "\n",
    "def is_pinecone_empty(vector_store):\n",
    "    index = vector_store._index  # access underlying pinecone index\n",
    "    stats = index.describe_index_stats()\n",
    "    return stats[\"total_vector_count\"] == 0\n",
    "\n",
    "\n",
    "def mark_indexed(filename, file_hash):\n",
    "    db = json.load(open(INDEXED_FILE)) if os.path.exists(INDEXED_FILE) else {}\n",
    "    db[filename] = file_hash\n",
    "    json.dump(db, open(INDEXED_FILE, \"w\"))\n",
    "\n",
    "filename = \"test.md\"\n",
    "file_hash = get_file_hash(filename)\n",
    "\n",
    "if is_already_indexed(filename, file_hash):\n",
    "    print(\"already indexed, skipping\")\n",
    "else:\n",
    "    headers_to_split_on = [\n",
    "        (\"##\", \"section\"),\n",
    "        (\"###\", \"subsection\"),\n",
    "    ]\n",
    "    splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        md_text = f.read()\n",
    "\n",
    "    chunks = splitter.split_text(md_text)\n",
    "    if is_pinecone_empty(vector_store):\n",
    "        vector_store.add_documents(chunks)\n",
    "        mark_indexed(filename, file_hash)\n",
    "        print(f\"indexed {len(chunks)} chunks\")\n",
    "    else:\n",
    "        mark_indexed(filename, file_hash)  # sync the hash so future runs skip correctly\n",
    "        print(f\"Pinecone already has data ({index.describe_index_stats()['total_vector_count']} vectors), skipping upsert\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80feb7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Literal, Optional, List\n",
    "from langchain_openai import ChatOpenAI\n",
    "# from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# query = \"what did aayushmaan study at unsw?\"\n",
    "\n",
    "class Filter(BaseModel):\n",
    "    sections: List[Literal[\n",
    "        \"Projects\", \"Technical Skills\", \"Work Experience\",\n",
    "        \"Education\", \"Frequently Asked Questions (for RAG)\",\n",
    "        \"Recruiter FAQ — AI & Applied AI Experience\",\n",
    "        \"Life Journey (Timeline)\", \"Family\", \"Sports Achievements\"\n",
    "    ]]\n",
    "    subsection: Optional[str] = None  # not always needed\n",
    "\n",
    "filter_llm = init_chat_model(\"o3-mini\").with_structured_output(Filter)\n",
    "llm = init_chat_model(\"gpt-4o\")\n",
    "\n",
    "\n",
    "def get_filter(query):\n",
    "    return filter_llm.invoke(f\"\"\"\n",
    "You are a routing assistant for a personal knowledge base about Aayushmaan Hooda.\n",
    "\n",
    "Given this query: \"{query}\"\n",
    "\n",
    "Pick one or more relevant sections. Pick subsection only if the query is very specific.\n",
    "\n",
    "Available sections:\n",
    "- Projects\n",
    "- Technical Skills\n",
    "- Work Experience\n",
    "- Education\n",
    "- Frequently Asked Questions (for RAG)\n",
    "- Recruiter FAQ — AI & Applied AI Experience\n",
    "- Life Journey (Timeline)\n",
    "- Family\n",
    "- Sports Achievements\n",
    "\"\"\")\n",
    "\n",
    "# result = get_filter(query)\n",
    "\n",
    "# search_filter = {\"section\": {\"$in\": result.sections}}\n",
    "# if result.subsection:\n",
    "#     search_filter[\"subsection\"] = result.subsection\n",
    "\n",
    "# retriever = vector_store.as_retriever(\n",
    "#     search_kwargs={\"k\": 3, \"filter\": search_filter}\n",
    "# )\n",
    "\n",
    "# retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0a2c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain_tavily import TavilySearch\n",
    "from datetime import datetime\n",
    "\n",
    "web_search = TavilySearch(max_results=2)\n",
    "\n",
    "@tool\n",
    "def rag_tool(query: str):\n",
    "    \" This is retriever tool, retrieve all info about aayushmaan for this tool\"\n",
    "    result = get_filter(query)\n",
    "\n",
    "    search_filter = {\"section\": {\"$in\": result.sections}}\n",
    "    if result.subsection:\n",
    "        search_filter[\"subsection\"] = result.subsection\n",
    "\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "            query, \n",
    "            k=3, \n",
    "            filter=search_filter\n",
    "        )\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "\n",
    "@tool\n",
    "def web_search_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Use this tool to search the web when the user asks about current events,\n",
    "    news, or things not in the local knowledge.\n",
    "    Input: query (str) - the search term.\n",
    "    Output: short text with titles and urls of results.\n",
    "    \"\"\"\n",
    "    res = web_search.invoke({\"query\": query})\n",
    "    return res[\"results\"]\n",
    "\n",
    "@tool\n",
    "def age_calculator() -> str:\n",
    "    \"\"\"\n",
    "    Use when age is asked\n",
    "    Calculate age from a hardcoded date of birth (30 August 1999).\n",
    "    Returns the current age as an integer of aayushmaan.\n",
    "    \"\"\"\n",
    "    dob = datetime(1999, 8, 30)\n",
    "    today = datetime.now()\n",
    "    \n",
    "    age = today.year - dob.year\n",
    "    \n",
    "    # Adjust if birthday hasn't occurred this year\n",
    "    if (today.month, today.day) < (dob.month, dob.day):\n",
    "        age -= 1\n",
    "    \n",
    "    return f\"Current age: {age} years old (DOB: 30 August 1999)\"\n",
    "\n",
    "@tool\n",
    "def calendar_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Use this tool for any date/time/calendar related questions.\n",
    "    Provides current date, time, day of week, and can calculate\n",
    "    days between dates or upcoming events.\n",
    "    \"\"\"\n",
    "    now = datetime.now()\n",
    "    \n",
    "    return f\"\"\"\n",
    "        Current date: {now.strftime(\"%A, %d %B %Y\")}\n",
    "        Current time: {now.strftime(\"%I:%M %p\")}\n",
    "        Day of week: {now.strftime(\"%A\")}\n",
    "        Week number: {now.strftime(\"%W\")}\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee9398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from app.prompts import system_prompt\n",
    "\n",
    "tools = [rag_tool, web_search_tool, age_calculator, calendar_tool]\n",
    "# If desired, specify custom instructions\n",
    "prompt = system_prompt\n",
    "agent = create_agent(llm, tools, system_prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58f34484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is dat etoday?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  calendar_tool (call_uFzQ8OuUjZ7smokNmIumP76v)\n",
      " Call ID: call_uFzQ8OuUjZ7smokNmIumP76v\n",
      "  Args:\n",
      "    query: what is the date today?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: calendar_tool\n",
      "\n",
      "\n",
      "        Current date: Saturday, 21 February 2026\n",
      "        Current time: 10:45 AM\n",
      "        Day of week: Saturday\n",
      "        Week number: 07\n",
      "        \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Today is Saturday, 21st February 2026.\n"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "   \"what is dat etoday?\"\n",
    ")\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfb0791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Identity / basic\n",
    "# q1 = \"where is aayushmaan from?\"\n",
    "# q2 = \"what is aayushmaan's email and github?\"\n",
    "\n",
    "# # Work experience\n",
    "# q3 = \"what did aayushmaan do at annalect?\"\n",
    "# q4 = \"tell me about the stoik internship\"\n",
    "\n",
    "# # Projects\n",
    "# q5 = \"tell me about the voice rag project\"\n",
    "# q6 = \"what is the leave manager mcp server?\"\n",
    "\n",
    "# # Skills\n",
    "# q7 = \"what databases does aayushmaan use?\"\n",
    "\n",
    "# # Education\n",
    "# q8 = \"what did aayushmaan study at unsw?\"\n",
    "\n",
    "# # Recruiter style\n",
    "# q9 = \"can aayushmaan build end to end AI applications?\"\n",
    "# q10 = \"what makes aayushmaan different from other AI engineers?\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botv4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
